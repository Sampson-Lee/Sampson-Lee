<h1 align="center"><img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Hi.gif" width="29px"> <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Earth.gif" width="24px"> Hi, I'm Xinpeng (Sampson) Li.</h1>

## About me
<a target="_blank" align="center">
  <img align="right" top="500" height="140" width="250" alt="GIF" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/photos.gif">
</a>

- ðŸŽ“ Incoming PhD candidate at [CS](https://cs.utdallas.edu/) of [UTD](https://www.utdallas.edu/), advised by [Yapeng Tian](https://www.yapengtian.com/). Here is [CV](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/CV_XinpengLi_2024.pdf).
- ðŸ‘€ Currently engaged in artificial intelligence and affect computing research.
- ðŸ“« Feel free to reach out at (+86) 188 2607 4990 or li.xin.peng@outlook.com.


## Publications 

[<img align="left" height="90px" width="120px" alt="TMM'23" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/TMM_2023_VERT_logo.png"/>]()
VERT: End-to-End Visual Emotion Recognition with Subject-Context Transformers. \
**Xinpeng Li**, Teng Wang, Shuyi Mao, Jinbao Wang, Xiaojiang Peng, and Feng Zheng.  \
[Paper](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/VERT_Submitted_Version.pdf) (Submitted version) & Code will come soon. \
Submitted to **TMM'23**.

<br/>
<br/>

[<img align="left" height="90px" width="120px" alt="NeurIPS'23" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/NeurIPS_2023_Real3D_AD_logo.png"/>]()
Real3D-AD: A Dataset of Point Cloud Anomaly Detection. \
Jiaqi Liu, Guoyang Xie, Ruitao Chen, **Xinpeng Li**, Jinbao Wang, Yong Liu, Chengjie Wang, Feng Zheng. \
[Paper](https://arxiv.org/pdf/2309.13226.pdf)  & [Code](https://github.com/M-3LAB/Real3D-AD). \
Accepted by **NeurIPS'23**.

<br/>
<br/>

[<img align="left" height="90px" width="120px" alt="TMM'23" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/TMM_2023_AUX_logo.png"/>]()
Facial Action Units as A Bridge of Joint Dataset Training for Facial Expression Recognition. \
Shuyi Mao, **Xinpeng Li**, Fan Zhang, Xiaojiang Peng, and Yang Yang. \
[Paper](https://arxiv.org/pdf/2211.06609.pdf) (Preliminary version) & Code will come soon. \
Submitted to **TMM'23**.

<br/>
<br/>

[<img align="left" height="90px" width="120px" alt="ACMMM'22" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection_logo.png"/>]()
Rail Detection: An Efficient Row-based Network and a New Benchmark. \
**Xinpeng Li**, and Xiaojiang Peng. \
[Paper](https://arxiv.org/pdf/2304.05667.pdf) & [Code](https://github.com/Sampson-Lee/Rail-Detection). \
Accepted by **ACMMM'22**.

<br/>
<br/>

[<img align="left" height="90px" width="120px" alt="IJCB'21" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net_logo.png"/>]()
Sequential Interactive Biased Network for Context-Aware Emotion Recognition. \
**Xinpeng Li**, Xiaojiang Peng, and Changxing Ding. \
[Paper](https://ieeexplore.ieee.org/document/9484370) & [Code](https://github.com/Sampson-Lee/SIB-Net). \
Accepted by **IJCB'21**.


<br/>
