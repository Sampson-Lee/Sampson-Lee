<h1 align="center"><img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Hi.gif" width="29px"> <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Earth.gif" width="24px"> I'm Xinpeng (Sampson) Li.</h1>
<h3 align="center">Have fun, do research. </h3>
<a target="_blank" align="center">
  <img align="right" top="500" height="300" width="400" alt="GIF" src="https://media.giphy.com/media/SWoSkN6DxTszqIKEqv/giphy.gif">
</a>

## About
- üëÄ I‚Äôm interested in facial expression-related tasks that include detection, recognition, comparison, and synthesis. So far, I propose [SIB-Net](https://github.com/Sampson-Lee/SIB-Net) [[1]](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net.pdf), [Rail-Net](https://github.com/Sampson-Lee/Rail-Detection) [[2]](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection.pdf), and AU-ViT [3] in the computer vision field.
- üå± I‚Äôm currently learning computer vision and graphics, English writing, and optimization. I resort to updating videos to **[Bilibili](https://space.bilibili.com/111355637/)** for self-motivation and self-improvement.
- üíûÔ∏è I‚Äôm looking for a Ph.D. position, collaborators and a girlfriend :-).
- üì´ If you have questions, please do not hesitate to contact me at **(+86) 188 2607 4990** or **li.xin.peng@outlook.com**.
- üìÑ Know about my experiences <a href="https://github.com/100rabhcsmc/Me.io/blob/master/01SaurabhChavanReactNativeResume.pdf" target="blank">Resume</a>
 
 
<br/>
<br/>

## Publications

[<img align="left" height="94px" width="94px" alt="IJCB" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net_logo.png"/>]()
(IJCB 2021) Sequential Interactive Biased Network for Context-Aware Emotion Recognition. \
**Li, X.**, Peng, X., & Ding, C. \
[**Paper**](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net.pdf) & [**Code**](https://github.com/Sampson-Lee/SIB-Net). \
In 2021 IEEE IJCB (pp. 1-6).

<br/>
<br/>

[<img align="left" height="94px" width="94px" alt="ACMMM" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection_logo.png"/>]()
(ACM MM 2022) Rail Detection: An Efficient Row-based Network and a New Benchmark. \
**Li, X.**, Peng, X. \
[**Paper**](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection.pdf) & [**Code**](https://github.com/Sampson-Lee/Rail-Detection). \
In Proceedings of the 30th ACM MM (pp. 6455-6463).

<br/>
<br/>

[<img align="left" height="94px" width="94px" alt="TIP" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/TIP_2022_AU_ViT_logo.png"/>]()
(ACM MM 2022) AU-Aware Vision Transformers for Biased Facial Expression Recognition. \
**S. Mao, X. Li**, Q. Wu, and X. Peng. \
[**Paper**]() & [**Code**]() will come soon. \
Submitted to Transactions on Image Processing (TIP).

<br/>
<br/>

