<h1 align="center"><img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Hi.gif" width="29px"> <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Earth.gif" width="24px"> Hi, I'm Xinpeng (Sampson) Li.</h1>
<h3 align="center">Have fun, get things done. </h3>

## About me
<a target="_blank" align="center">
  <img align="right" top="500" height="200" width="300" alt="GIF" src="https://media.giphy.com/media/SWoSkN6DxTszqIKEqv/giphy.gif">
</a>

- üëÄ I focus on facial expression-related tasks that include detection, recognition, comparison, and synthesis. I am also interested in a wide range of computer vision tasks.
- üå± I‚Äôm currently learning computer vision and graphics, English writing, and optimization. I enjoy learning and updating videos to **[Bilibili](https://space.bilibili.com/111355637/)**. 
- üéì I got a bachelor's and master's degree from South China University of Technology (Ranked #20 in China). I was supervised by Prof. [Dacheng Tao](https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=zh-CN&oi=ao), Prof. [Changxing Ding](https://scholar.google.com/citations?user=8Z8jplgAAAAJ&hl=zh-CN&oi=ao), and Prof. [Xiaojiang Peng](https://scholar.google.com/citations?user=7oRD67kAAAAJ&hl=zh-CN&oi=ao). Here is my **[CV](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/CV%20XinpengLi%202022.pdf)**.
- üíûÔ∏è I‚Äôm looking for **a Ph.D. position** :-).
- üì´ If you want to ask questions or share stories, please do not hesitate to contact me at **(+86) 188 2607 4990** or **li.xin.peng@outlook.com**.


## Publications

[<img align="left" height="94px" width="94px" alt="IJCB" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net_logo.png"/>]()
Sequential Interactive Biased Network for Context-Aware Emotion Recognition. \
**Li, X.**, Peng, X., & Ding, C. \
[**Paper**](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/IJCB_2021_SCB_Net.pdf) & [**Code**](https://github.com/Sampson-Lee/SIB-Net). \
In the 2021 IEEE IJCB (pp. 1-6).

<br/>
<br/>

[<img align="left" height="94px" width="94px" alt="ACMMM" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection_logo.png"/>]()
Rail Detection: An Efficient Row-based Network and a New Benchmark. \
**Li, X.**, Peng, X. \
[**Paper**](https://github.com/Sampson-Lee/Sampson-Lee/blob/main/ACM_MM_2022_Rail_Detection.pdf) & [**Code**](https://github.com/Sampson-Lee/Rail-Detection). \
In Proceedings of the 30th ACM MM (pp. 6455-6463).

<br/>
<br/>

[<img align="left" height="94px" width="94px" alt="TIP" src="https://github.com/Sampson-Lee/Sampson-Lee/blob/main/TIP_2022_AU_ViT_logo.png"/>]()
AU-Aware Vision Transformers for Biased Facial Expression Recognition. \
**S. Mao**\*, **X. Li**\*, Q. Wu, and X. Peng. (\* means equal contribution.)\
[**Paper**]() & [**Code**]() will come soon. \
Submitted to the Transactions on Image Processing (TIP).

